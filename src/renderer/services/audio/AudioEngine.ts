/**
 * AURA Cloud Studio - Audio Engine Core
 *
 * ê¸°ìˆ  ìŠ¤íƒ í•©ì˜ì„œ ê¸°ì¤€:
 * - Tone.js: ë©”ì¸ ì˜¤ë””ì˜¤ ì—”ì§„ (Web Audio API ì¶”ìƒí™”)
 * - TypeScript: íƒ€ì… ì•ˆì •ì„±
 *
 * í•µì‹¬ API êµ¬ì¡°:
 * - TransportAPI: play(), stop(), setBpm() / íƒ€ì„ë¼ì¸ ë™ê¸°í™”
 * - SmartInstrumentAPI: loadKit(), kitMorph(genre) / í•«ìŠ¤ì™‘ ì§€ì›
 * - MacroEffectAPI: setSmartKnob(trackType, value) / EQ+Comp+Reverb ë™ì‹œ ì œì–´
 */

import * as Tone from 'tone';
import {
  InstrumentType,
  TrackState,
  TrackOptions,
  PlaybackState,
  TransportState,
  AudioEngineState,
  AudioEngineOptions,
  SMART_KNOB_PROFILES,
  EffectType,
} from '../../types/audio.types';
import { InstrumentTrack } from './InstrumentTrack';
import { SmartKnobProcessor } from './SmartKnobProcessor';

/**
 * AudioEngine - AURA Cloud Studioì˜ í•µì‹¬ ì˜¤ë””ì˜¤ ì—”ì§„
 *
 * Singleton íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ì „ì—­ì—ì„œ í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë§Œ ì‚¬ìš©
 */
export class AudioEngine {
  private static instance: AudioEngine | null = null;

  // Tone.js ì»´í¬ë„ŒíŠ¸
  private masterGain: Tone.Gain;
  private limiter: Tone.Limiter;
  private masterAnalyser: Tone.Analyser;

  // íŠ¸ë™ ê´€ë¦¬
  private tracks: Map<string, InstrumentTrack> = new Map();

  // Smart Knob í”„ë¡œì„¸ì„œ
  private smartKnobProcessor: SmartKnobProcessor;

  // ìƒíƒœ
  private _isInitialized: boolean = false;
  private _masterVolume: number = 0; // dB
  private _timeSignature: [number, number] = [4, 4]; // [CRITICAL FIX] Cache TS locally

  // ìƒíƒœ ë³€ê²½ ë¦¬ìŠ¤ë„ˆ (Zustand ì—°ë™ìš©)
  private stateChangeListeners: Set<(state: AudioEngineState) => void> = new Set();

  // Playhead ì¶”ì 
  private positionUpdateInterval: ReturnType<typeof setInterval> | null = null;
  private positionChangeListeners: Set<(position: number) => void> = new Set();
  private _currentPositionSeconds: number = 0;

  private constructor() {
    // Master ì¶œë ¥ ì²´ì¸: Gain -> Limiter -> Destination
    this.masterGain = new Tone.Gain(1);
    this.limiter = new Tone.Limiter(-1);

    // FAN-OUT ROUTING Strategy:
    // 1. Audio Path: Gain -> Limiter -> Destination (Ensure Sound!)
    this.masterGain.connect(this.limiter);
    this.limiter.toDestination();

    // 2. Visual Path: Gain -> Analyser (Side-chain for Visuals)
    this.masterAnalyser = new Tone.Analyser('waveform', 256);
    this.masterGain.connect(this.masterAnalyser);

    // [CRITICAL FIX] Force Wake: Connect Analyser to silent destination
    // Web Audio optimization might silence disconnected nodes.
    const dummyGain = new Tone.Gain(0).toDestination();
    this.masterAnalyser.connect(dummyGain);

    // Smart Knob í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    this.smartKnobProcessor = new SmartKnobProcessor();
  }

  /**
   * Singleton ì¸ìŠ¤í„´ìŠ¤ íšë“
   */
  public static getInstance(): AudioEngine {
    if (!AudioEngine.instance) {
      AudioEngine.instance = new AudioEngine();
    }
    return AudioEngine.instance;
  }

  // ============================================
  // ì´ˆê¸°í™” ë° Context ê´€ë¦¬
  // ============================================

  /**
   * ì™¸ë¶€ ì˜¤ë””ì˜¤ ë…¸ë“œë¥¼ ë§ˆìŠ¤í„° ë²„ìŠ¤ì— ì—°ê²°
   */
  public connectToMaster(node: Tone.ToneAudioNode): void {
    node.connect(this.masterGain);
  }

  /**
   * ë§ˆìŠ¤í„° ì…ë ¥ ë…¸ë“œ ë°˜í™˜ (ì§ì ‘ ì—°ê²°ìš©)
   */
  public get masterInput(): Tone.Gain {
    return this.masterGain;
  }

  /**
   * ë§ˆìŠ¤í„° ì›¨ì´ë¸Œí¼ ë°ì´í„° ì¡°íšŒ
   */
  public getWaveformData(): Float32Array {
    // masterAnalyserê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ëŒ€ë¹„
    if (!this.masterAnalyser) return new Float32Array(0);
    return this.masterAnalyser.getValue() as Float32Array;
  }

  /**
   * ì‹œê°í™” ì „ìš© ì—°ê²° (ì˜¤ë””ì˜¤ ì¶œë ¥ ì—†ìŒ, ì›¨ì´ë¸Œí¼ ë¶„ì„ë§Œ ìˆ˜í–‰)
   * Safe Mode: Audio Pathì™€ ë¶„ë¦¬í•˜ì—¬ ì‹œê°í™” ìˆ˜í–‰
   */
  public connectToVisualizer(node: Tone.ToneAudioNode): void {
    if (this.masterAnalyser) {
      console.log('[AudioEngine] Connecting node to visualizer:', node);
      node.connect(this.masterAnalyser);
    } else {
      console.warn('[AudioEngine] Visualizer connection failed: Master Analyser is null');
    }
  }

  /**
   * ì‹œê°í™” ì…ë ¥ ë…¸ë“œ ë°˜í™˜ (SynthDrums ë“± Wrapper í´ë˜ìŠ¤ ì—°ê²°ìš©)
   */
  public get visualizerInput(): Tone.ToneAudioNode {
    return this.masterAnalyser;
  }

  /**
   * ì˜¤ë””ì˜¤ ì—”ì§„ ì´ˆê¸°í™”
   * ì‚¬ìš©ì ì œìŠ¤ì²˜ í›„ í˜¸ì¶œë˜ì–´ì•¼ í•¨ (Web Audio API ì •ì±…)
   */
  public async initialize(options: AudioEngineOptions = {}): Promise<void> {
    if (this._isInitialized) {
      console.warn('AudioEngine already initialized');
      return;
    }

    try {
      // Tone.js Context ì‹œì‘
      await Tone.start();
      console.log('Tone.js context started');

      // Transport ì„¤ì •
      const { bpm = 120, timeSignature = [4, 4], masterVolume = 0 } = options;

      Tone.getTransport().bpm.value = bpm;
      Tone.getTransport().timeSignature = timeSignature;
      this._timeSignature = timeSignature as [number, number]; // Sync local cache

      this.setMasterVolume(masterVolume);

      this._isInitialized = true;
      this.notifyStateChange();

      console.log(`AudioEngine initialized: BPM=${bpm}, TimeSignature=${timeSignature}`);
    } catch (error) {
      console.error('Failed to initialize AudioEngine:', error);
      throw error;
    }
  }

  /**
   * Context ìƒíƒœ í™•ì¸
   */
  public get isContextRunning(): boolean {
    return Tone.getContext().state === 'running';
  }

  /**
   * ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
   */
  public get isInitialized(): boolean {
    return this._isInitialized;
  }

  // ============================================
  // TransportAPI - ì¬ìƒ ì œì–´
  // ============================================

  /**
   * ì¬ìƒ ì‹œì‘
   */
  public play(startTime?: string): void {
    if (!this._isInitialized) {
      console.warn('AudioEngine not initialized');
      return;
    }

    const transport = Tone.getTransport();

    if (startTime) {
      transport.position = startTime;
    }

    transport.start();
    this.startPositionTracking();
    this.notifyStateChange();
  }

  /**
   * ì¬ìƒ ì •ì§€ (ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°)
   */
  public stop(): void {
    const transport = Tone.getTransport();
    transport.stop();
    transport.position = 0;
    this._currentPositionSeconds = 0;
    this.stopPositionTracking();
    this.notifyPositionChange(0);
    this.notifyStateChange();
  }

  /**
   * í˜„ì¬ ì¬ìƒ ì¤‘ì¸ì§€ í™•ì¸
   */
  public get isPlaying(): boolean {
    return Tone.getTransport().state === 'started';
  }

  /**
   * í˜„ì¬ ì¬ìƒ ìƒíƒœ ë°˜í™˜
   */
  public get playbackState(): PlaybackState {
    const state = Tone.getTransport().state;
    switch (state) {
      case 'started':
        return 'playing';
      case 'paused':
        return 'paused';
      default:
        return 'stopped';
    }
  }

  /**
   * BPM ì„¤ì •
   */
  public setBpm(bpm: number): void {
    if (bpm < 20 || bpm > 300) {
      console.warn('BPM out of range (20-300):', bpm);
      return;
    }

    Tone.getTransport().bpm.value = bpm;
    this.notifyStateChange();
  }

  /**
   * BPM ì¡°íšŒ
   */
  public get bpm(): number {
    return Tone.getTransport().bpm.value;
  }

  /**
   * ë°•ìí‘œ ì„¤ì •
   */
  public setTimeSignature(numerator: number, denominator: number): void {
    Tone.getTransport().timeSignature = [numerator, denominator];
    this._timeSignature = [numerator, denominator]; // Update local cache
    this.notifyStateChange();
  }

  /**
   * í˜„ì¬ ì¬ìƒ ìœ„ì¹˜ ì¡°íšŒ
   */
  public get position(): string {
    return Tone.getTransport().position.toString();
  }

  /**
   * ì¬ìƒ ìœ„ì¹˜ ì„¤ì •
   */
  public setPosition(position: string): void {
    Tone.getTransport().position = position;
    this.notifyStateChange();
  }

  /**
   * ë£¨í”„ ì„¤ì •
   */
  public setLoop(enabled: boolean, start?: string, end?: string): void {
    const transport = Tone.getTransport();
    transport.loop = enabled;

    if (start) transport.loopStart = start;
    if (end) transport.loopEnd = end;

    this.notifyStateChange();
  }

  // ============================================
  // Playhead Tracking - ìœ„ì¹˜ ì¶”ì  ì‹œìŠ¤í…œ
  // ============================================

  /**
   * í˜„ì¬ ìœ„ì¹˜ (ì´ˆ ë‹¨ìœ„)
   */
  public getCurrentPosition(): number {
    return this._currentPositionSeconds;
  }

  /**
   * í˜„ì¬ ìœ„ì¹˜ (Bar:Beat:Sixteenth í˜•ì‹)
   */
  public getCurrentPositionBBS(): string {
    return Tone.getTransport().position.toString();
  }

  /**
   * ìœ„ì¹˜ ë³€ê²½ ì½œë°± ë“±ë¡
   */
  public onPositionChange(callback: (positionSeconds: number) => void): () => void {
    this.positionChangeListeners.add(callback);

    // êµ¬ë… í•´ì œ í•¨ìˆ˜ ë°˜í™˜
    return () => {
      this.positionChangeListeners.delete(callback);
    };
  }

  /**
   * ìœ„ì¹˜ ì¶”ì  ì‹œì‘ (ì¬ìƒ ì‹œ í˜¸ì¶œ)
   */
  private startPositionTracking(): void {
    // ê¸°ì¡´ interval ì •ë¦¬
    this.stopPositionTracking();

    // 60fpsì— ê°€ê¹Œìš´ ì—…ë°ì´íŠ¸ (ì•½ 16.67ms)
    this.positionUpdateInterval = setInterval(() => {
      const transport = Tone.getTransport();
      this._currentPositionSeconds = transport.seconds;
      this.notifyPositionChange(this._currentPositionSeconds);
    }, 16);
  }

  /**
   * ìœ„ì¹˜ ì¶”ì  ì¤‘ì§€ (ì •ì§€ ì‹œ í˜¸ì¶œ)
   */
  private stopPositionTracking(): void {
    if (this.positionUpdateInterval) {
      clearInterval(this.positionUpdateInterval);
      this.positionUpdateInterval = null;
    }
  }

  /**
   * ìœ„ì¹˜ ë³€ê²½ ì•Œë¦¼
   */
  private notifyPositionChange(positionSeconds: number): void {
    this.positionChangeListeners.forEach(listener => listener(positionSeconds));
  }

  // ============================================
  // Master Volume Control
  // ============================================

  /**
   * ë§ˆìŠ¤í„° ë³¼ë¥¨ ì„¤ì • (dB)
   */
  public setMasterVolume(volumeDb: number): void {
    const clampedVolume = Math.max(-60, Math.min(6, volumeDb));
    this._masterVolume = clampedVolume;
    this.masterGain.gain.value = Tone.gainToDb(Tone.dbToGain(clampedVolume));
    this.notifyStateChange();
  }

  /**
   * ğŸ¦† [UNICORN] Audio Ducking Control
   * Reduces master volume temporarily during voice interaction.
   * Target: -15dB (Approx 20% volume)
   */
  public setDucking(active: boolean): void {
    const targetDb = active ? -20 : this._masterVolume; // -20dB vs Original Volume
    const rampTime = active ? 0.2 : 1.0; // Fast Duck (0.2s), Slow Release (1.0s)

    console.log(`[AudioEngine] Ducking: ${active ? 'ON (-20dB)' : 'OFF (Restore)'}`);

    // Use rampTo for smooth transition without clicking
    this.masterGain.gain.rampTo(Tone.dbToGain(targetDb), rampTime);
  }

  /**
   * ë§ˆìŠ¤í„° ë³¼ë¥¨ ì¡°íšŒ
   */
  public get masterVolume(): number {
    return this._masterVolume;
  }

  // ============================================
  // Track Management
  // ============================================

  /**
   * ìƒˆ íŠ¸ë™ ìƒì„±
   */
  public createTrack(options: TrackOptions = {}): InstrumentTrack {
    const track = new InstrumentTrack(options, this.masterGain, this.smartKnobProcessor);
    this.tracks.set(track.id, track);
    this.notifyStateChange();
    return track;
  }

  /**
   * íŠ¸ë™ ì¡°íšŒ
   */
  public getTrack(trackId: string): InstrumentTrack | undefined {
    return this.tracks.get(trackId);
  }

  /**
   * íŠ¸ë™ ì‚­ì œ
   */
  public deleteTrack(trackId: string): boolean {
    const track = this.tracks.get(trackId);
    if (track) {
      track.dispose();
      this.tracks.delete(trackId);
      this.notifyStateChange();
      return true;
    }
    return false;
  }

  /**
   * ëª¨ë“  íŠ¸ë™ ì¡°íšŒ
   */
  public getAllTracks(): InstrumentTrack[] {
    return Array.from(this.tracks.values());
  }

  /**
   * ì†”ë¡œ ìƒíƒœ ê´€ë¦¬ (í•˜ë‚˜ì˜ íŠ¸ë™ë§Œ ì†”ë¡œì¼ ë•Œ ë‚˜ë¨¸ì§€ ë®¤íŠ¸)
   */
  public updateSoloState(): void {
    const tracks = this.getAllTracks();
    const hasSoloTrack = tracks.some(track => track.solo);

    tracks.forEach(track => {
      if (hasSoloTrack) {
        // ì†”ë¡œ íŠ¸ë™ì´ ìˆìœ¼ë©´ ì†”ë¡œê°€ ì•„ë‹Œ íŠ¸ë™ì€ ë®¤íŠ¸
        track.setEffectiveMute(!track.solo);
      } else {
        // ì†”ë¡œ íŠ¸ë™ì´ ì—†ìœ¼ë©´ ê°œë³„ ë®¤íŠ¸ ìƒíƒœ ì ìš©
        track.setEffectiveMute(track.mute);
      }
    });

    this.notifyStateChange();
  }

  // ============================================
  // SmartInstrumentAPI
  // ============================================

  /**
   * íŠ¸ë™ì˜ ì•…ê¸° íƒ€ì… ë³€ê²½ (í•«ìŠ¤ì™‘)
   */
  public setTrackInstrumentType(trackId: string, instrumentType: InstrumentType): void {
    const track = this.tracks.get(trackId);
    if (track) {
      track.setInstrumentType(instrumentType);
      this.notifyStateChange();
    }
  }

  /**
   * Kit Morph - ì¥ë¥´ì— ë§ëŠ” ìƒ˜í”Œ ì„¸íŠ¸ë¡œ ë³€ê²½ (í–¥í›„ êµ¬í˜„)
   */
  public async kitMorph(trackId: string, genre: string): Promise<void> {
    // TODO: AI ê¸°ë°˜ ìƒ˜í”Œ ë§¤ì¹­ ë¡œì§ êµ¬í˜„
    console.log(`Kit morph requested for track ${trackId} to genre: ${genre}`);
  }

  // ============================================
  // MacroEffectAPI - Smart Knob
  // ============================================

  /**
   * Smart Knob ê°’ ì„¤ì •
   * ì•…ê¸° íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì´í™íŠ¸ ì²´ì¸ì´ ìë™ìœ¼ë¡œ ì¡°ì ˆë¨
   *
   * @param trackId íŠ¸ë™ ID
   * @param value ë…¸ë¸Œ ê°’ (0-100)
   */
  public setSmartKnob(trackId: string, value: number): void {
    const track = this.tracks.get(trackId);
    if (!track) {
      console.warn(`Track not found: ${trackId}`);
      return;
    }

    // ê°’ ë²”ìœ„ ì œí•œ
    const clampedValue = Math.max(0, Math.min(100, value));

    // Smart Knob í”„ë¡œì„¸ì„œë¥¼ í†µí•´ ì´í™íŠ¸ ì ìš©
    this.smartKnobProcessor.applySmartKnob(track, clampedValue);

    this.notifyStateChange();
  }

  /**
   * íŠ¹ì • íŠ¸ë™ì˜ Smart Knob í”„ë¡œí•„ ì¡°íšŒ
   */
  public getSmartKnobProfile(trackId: string): typeof SMART_KNOB_PROFILES[InstrumentType] | null {
    const track = this.tracks.get(trackId);
    if (!track) return null;

    return SMART_KNOB_PROFILES[track.instrumentType];
  }

  // ============================================
  // State Management (Zustand ì—°ë™)
  // ============================================

  /**
   * í˜„ì¬ ì—”ì§„ ìƒíƒœ ìŠ¤ëƒ…ìƒ·
   */
  public getState(): AudioEngineState {
    const transport = Tone.getTransport();

    return {
      isInitialized: this._isInitialized,
      isContextRunning: this.isContextRunning,
      masterVolume: this._masterVolume,
      transport: {
        playbackState: this.playbackState,
        isPlaying: this.isPlaying,
        bpm: transport.bpm.value,
        timeSignature: this._timeSignature,
        position: transport.position.toString(),
        positionSeconds: this._currentPositionSeconds,
        loop: transport.loop,
        loopStart: transport.loopStart.toString(),
        loopEnd: transport.loopEnd.toString(),
      },
      tracks: this.getAllTracks().map(track => track.getState()),
    };
  }

  /**
   * ìƒíƒœ ë³€ê²½ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
   */
  public subscribe(listener: (state: AudioEngineState) => void): () => void {
    this.stateChangeListeners.add(listener);

    // êµ¬ë… í•´ì œ í•¨ìˆ˜ ë°˜í™˜
    return () => {
      this.stateChangeListeners.delete(listener);
    };
  }

  /**
   * ìƒíƒœ ë³€ê²½ ì•Œë¦¼
   */
  private notifyStateChange(): void {
    const state = this.getState();
    this.stateChangeListeners.forEach(listener => listener(state));
  }

  // ============================================
  // Cleanup
  // ============================================

  /**
   * ì—”ì§„ ì •ë¦¬ (ë©”ëª¨ë¦¬ í•´ì œ)
   */
  public dispose(): void {
    // ëª¨ë“  íŠ¸ë™ ì •ë¦¬
    this.tracks.forEach(track => track.dispose());
    this.tracks.clear();

    // Transport ì •ì§€
    Tone.getTransport().stop();
    Tone.getTransport().cancel();

    // Master ì²´ì¸ ì •ë¦¬
    this.masterGain.disconnect();
    this.limiter.disconnect();

    this._isInitialized = false;
    this.stateChangeListeners.clear();

    AudioEngine.instance = null;
  }
}

// í¸ì˜ë¥¼ ìœ„í•œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ export
export const audioEngine = AudioEngine.getInstance();
